# app.py
import io
import os
import re
import time
import urllib.error
from datetime import datetime

import pandas as pd
import streamlit as st

# --- (ì„ íƒ) ì“°ê¸° ê¸°ëŠ¥ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬: ì„œë¹„ìŠ¤ ê³„ì •ì´ ìˆì„ ë•Œë§Œ ì‚¬ìš© ---
HAS_SERVICE_ACCOUNT = False
try:
    from google.oauth2.service_account import Credentials
    import gspread
    HAS_SERVICE_ACCOUNT = True
except Exception:
    HAS_SERVICE_ACCOUNT = False

# =========================================================
# ì„¤ì • ì˜ì—­
# =========================================================

# 1) ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ID  (ì—¬ê¸°ì— "í•œ ê°œ" IDë¥¼ ë„£ìœ¼ì„¸ìš”)
SPREADSHEET_ID = "1QQvBxuB1v8au2e7u22XzhZ9ov-SSQReutDGMKS31gvQ"

# 2) ê° ì‹œíŠ¸ì˜ gid (íƒ­ì„ ì—´ë©´ URL ëì˜ #gid=XXXXX ê°’)
GID_STUDENTS = "1030356842"   # ì˜ˆ: í•™ìƒëª…ë‹¨
GID_LOGS     = "0"            # ì˜ˆ: ìƒë‹´ì¼ì§€
GID_SCHOLAR  = "1878696825"   # ì˜ˆ: ì¥í•™ê¸ˆ ì§€ì›

# 3) CSV Export Base
BASE = f"https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/export?format=csv&gid="

# 4) ìƒë‹´ì¼ì§€ ì‹œíŠ¸ ì´ë¦„(ì“°ê¸° ëª¨ë“œì—ì„œ ì‚¬ìš©)
SHEET_NAME_LOGS = "ìƒë‹´ì¼ì§€"

# 5) ì›Œë“œí´ë¼ìš°ë“œ/í‚¤ì›Œë“œìš© ìµœì†Œ í† í° ê¸¸ì´/ë¶ˆìš©ì–´(ê°„ë‹¨)
KOREAN_STOPWORDS = set([
    "ì´", "ê·¸", "ì €", "ê²ƒ", "ìˆ˜", "ë“±", "ë“¤", "ë°", "ì œ",
    "ë…„", "ì›”", "ì¼", "ì‹œ", "ë¶„", "ì´ˆ", "ë•Œ", "ê²½ìš°", "ë•Œë¬¸",
    "ì‚¬ëŒ", "ë¬¸ì œ", "ë‚´ìš©", "ì •ë„", "ìì‹ ", "ìƒê°", "ë§ì”€",
    "ë„¤", "ì˜ˆ", "ì•„ë‹ˆìš”", "ìŒ", "ì–´", "ì•„", "ì €ê¸°",
    "ê·¸ë˜ì„œ", "ê·¸ëŸ¬ë‚˜", "í•˜ì§€ë§Œ", "ê·¸ë¦¬ê³ ", "ê·¸ëŸ°ë°",
    "ì¢€", "ë”", "ì˜", "ì•ˆ", "ëª»", "ë‹¤", "ë˜", "ê¼­",
    "ì°¸", "ì •ë§", "ì§„ì§œ", "ë„ˆë¬´", "ì•„ì£¼", "ë§¤ìš°"
])
PARTICLE_REGEX = re.compile(r"(ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ì˜|ì—|ì—ê²Œ|ì—ì„œ|ë¡œ|ìœ¼ë¡œ|ê³¼|ì™€|ë„|ë§Œ|ë³´ë‹¤|ì²˜ëŸ¼|ê¹Œì§€|ë§ˆì €|ì¡°ì°¨|ë¶€í„°|ì´ë‚˜|ê±°ë‚˜|í•˜ê³ |í•˜ë©°|í•´ì„œ|ì´ë‹¤|ì…ë‹ˆë‹¤|ìˆë‹¤|ì—†ë‹¤|ë©ë‹ˆë‹¤|ëœ|í•˜ëŠ”|ìˆëŠ”|ì—†ëŠ”|ì ì¸)$")

# =========================================================
# ìœ í‹¸ í•¨ìˆ˜
# =========================================================

def csv_url(gid: str) -> str:
    return BASE + str(gid)

def _read_csv(url: str) -> pd.DataFrame:
    # ë„¤íŠ¸ì›Œí¬/ê¶Œí•œ ë¬¸ì œ ëŒ€ë¹„: ì¬ì‹œë„ + ì¹œì ˆí•œ ì—ëŸ¬ ë©”ì‹œì§€
    last_err = None
    for _ in range(2):
        try:
            return pd.read_csv(url)
        except urllib.error.HTTPError as e:
            last_err = e
            time.sleep(0.6)
        except Exception as e:
            last_err = e
            break
    raise last_err

@st.cache_data(ttl=600, show_spinner="êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘â€¦")
def load_data():
    students = _read_csv(csv_url(GID_STUDENTS))
    logs = _read_csv(csv_url(GID_LOGS))
    scholar = _read_csv(csv_url(GID_SCHOLAR))
    return students, logs, scholar

def has_service_account() -> bool:
    # st.secretsì— gcp_service_accountê°€ ìˆìœ¼ë©´ True
    try:
        _ = st.secrets["gcp_service_account"]
        return True and HAS_SERVICE_ACCOUNT
    except Exception:
        return False

def append_log_to_sheet(row_values):
    """
    ì„œë¹„ìŠ¤ ê³„ì •ì´ ìˆì„ ë•Œë§Œ 'ìƒë‹´ì¼ì§€' ì‹œíŠ¸ì— í–‰ ì¶”ê°€.
    row_values: [íƒ€ì„ìŠ¤íƒ¬í”„, ì¥ì†Œ, í•™ë…„, ë°˜, ë²ˆí˜¸, ì´ë¦„, ìƒë‹´ë‚´ìš©, ë…¹ìŒíŒŒì¼ ì£¼ì†Œ]
    """
    if not has_service_account():
        return False, "ì„œë¹„ìŠ¤ ê³„ì •ì´ ì„¤ì •ë˜ì§€ ì•Šì•„, í˜„ì¬ëŠ” ë¡œì»¬(ì½ê¸°) ëª¨ë“œì…ë‹ˆë‹¤."

    try:
        sa_info = dict(st.secrets["gcp_service_account"])
        # êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì ‘ê·¼ ê¶Œí•œ ë²”ìœ„
        scopes = [
            "https://www.googleapis.com/auth/spreadsheets",
            "https://www.googleapis.com/auth/drive"
        ]
        creds = Credentials.from_service_account_info(sa_info, scopes=scopes)
        gc = gspread.authorize(creds)
        sh = gc.open_by_key(SPREADSHEET_ID)

        try:
            ws = sh.worksheet(SHEET_NAME_LOGS)
        except gspread.WorksheetNotFound:
            ws = sh.add_worksheet(title=SHEET_NAME_LOGS, rows=1000, cols=10)
            ws.append_row(["íƒ€ì„ìŠ¤íƒ¬í”„", "ì¥ì†Œ", "í•™ë…„", "ë°˜", "ë²ˆí˜¸", "ì´ë¦„", "ìƒë‹´ë‚´ìš©", "ë…¹ìŒíŒŒì¼ ì£¼ì†Œ"])

        ws.append_row(row_values)
        return True, "âœ… ìƒë‹´ ì¼ì§€ê°€ ì‹œíŠ¸ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."
    except Exception as e:
        return False, f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}"

def parse_amount_to_max_per_year(amount_str: str) -> int:
    """
    'ì—° 100~200ë§Œì›', 'ì›” 20~50ë§Œì›', 'ë¶„ê¸° ìµœëŒ€ 300ë§Œì›' ë“±ì—ì„œ ëŒ€ëµì  'ì—°ê°„ ìµœëŒ€ ê¸ˆì•¡(ë§Œì›)'ì„ ì¶”ì •
    """
    if not isinstance(amount_str, str):
        return 0
    nums = re.findall(r"\d+", amount_str)
    if not nums:
        return 0
    maxnum = max(int(n) for n in nums)
    # ë‹¨ìœ„ í™˜ì‚°
    if "ì›”" in amount_str:
        maxnum *= 12
    elif "ë¶„ê¸°" in amount_str:
        maxnum *= 4
    # 'ë§Œì›' ê°€ì •
    return maxnum

def process_text_for_keywords(text: str, topk: int = 20):
    if not isinstance(text, str) or not text.strip():
        return []
    # ê°„ë‹¨ ì „ì²˜ë¦¬
    text = re.sub(r"[^\w\sê°€-í£]", " ", text)
    tokens = [t for t in text.split() if len(t) >= 2]
    freq = {}
    for t in tokens:
        # ì¡°ì‚¬ ì œê±°
        t = PARTICLE_REGEX.sub("", t)
        if len(t) < 2: 
            continue
        if t in KOREAN_STOPWORDS:
            continue
        freq[t] = freq.get(t, 0) + 1
    # ìƒìœ„ Nê°œ
    items = sorted(freq.items(), key=lambda x: x[1], reverse=True)[:topk]
    return items

def chips_html(items):
    # í‚¤ì›Œë“œ chip ìŠ¤íƒ€ì¼ HTML
    html = []
    for w, _c in items:
        html.append(f"<span style='display:inline-block;margin:4px 6px;padding:6px 10px;border-radius:16px;background:#e3f2fd;color:#1976d2;font-weight:600'>#{w}</span>")
    return "".join(html)

# =========================================================
# UI
# =========================================================

st.set_page_config(page_title="ìƒë‹´ ì¼ì§€ ì‹œìŠ¤í…œ", layout="wide")

st.sidebar.title("ğŸ“š ìƒë‹´ ê´€ë¦¬")
menu = st.sidebar.radio("ë©”ë‰´", ["ì¼ì§€ ì‘ì„±", "ê¸°ë¡ ë³´ê¸°", "ì „ì²´ ìš”ì•½", "ì¥í•™ê¸ˆ ì§€ì›"], index=0)

# GID/ID ë¹ ë¥´ê²Œ ë°”ê¿€ ìˆ˜ ìˆê²Œ ì‚¬ì´ë“œë°”ì— í‘œì‹œ(í¸ì§‘ìš©)
with st.sidebar.expander("ì„¤ì •(ê´€ë¦¬ì)"):
    st.caption("ìŠ¤í”„ë ˆë“œì‹œíŠ¸/ì‹œíŠ¸ GID í™•ì¸ìš©")
    st.write("Spreadsheet ID:", SPREADSHEET_ID)
    st.write("í•™ìƒëª…ë‹¨ gid:", GID_STUDENTS)
    st.write("ìƒë‹´ì¼ì§€ gid:", GID_LOGS)
    st.write("ì¥í•™ê¸ˆ ì§€ì› gid:", GID_SCHOLAR)
    st.write("ì“°ê¸° ê°€ëŠ¥(ì„œë¹„ìŠ¤ê³„ì •):", "ê°€ëŠ¥ âœ…" if has_service_account() else "ì½ê¸° ì „ìš© ğŸ“´")

# ë°ì´í„° ë¡œë“œ
try:
    students_df, logs_df, scholar_df = load_data()
except Exception as e:
    st.error("âŒ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    st.info(
        "í™•ì¸í•´ì£¼ì„¸ìš”:\n"
        "1) ìŠ¤í”„ë ˆë“œì‹œíŠ¸ê°€ 'ë§í¬ê°€ ìˆëŠ” ëª¨ë“  ì‚¬ìš©ì(ë³´ê¸°ê°€ëŠ¥)'ë¡œ ê³µìœ ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n"
        "2) ê° ì‹œíŠ¸ gidê°€ ë§ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\n"
        "3) URL í˜•ì‹ì€ ë‹¤ìŒê³¼ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤:\n"
        f"   https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/export?format=csv&gid=<GID>\n"
        f"ì—ëŸ¬: {e}"
    )
    st.stop()

# --- í•™ìƒëª…ë‹¨ ì»¬ëŸ¼ í‘œì¤€í™”(ì˜ˆìƒ ì»¬ëŸ¼: í•™ë…„, ë°˜, ë²ˆí˜¸, ì´ë¦„) ---
expected_cols_students = ["í•™ë…„", "ë°˜", "ë²ˆí˜¸", "ì´ë¦„"]
missing_cols = [c for c in expected_cols_students if c not in students_df.columns]
if missing_cols:
    st.warning(f"í•™ìƒëª…ë‹¨ ì‹œíŠ¸ì— ë‹¤ìŒ ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤: {missing_cols}")

# --- ìƒë‹´ì¼ì§€ í‘œì¤€í™”(ì˜ˆìƒ ì»¬ëŸ¼) ---
expected_cols_logs = ["íƒ€ì„ìŠ¤íƒ¬í”„", "ì¥ì†Œ", "í•™ë…„", "ë°˜", "ë²ˆí˜¸", "ì´ë¦„", "ìƒë‹´ë‚´ìš©", "ë…¹ìŒíŒŒì¼ ì£¼ì†Œ"]
for c in expected_cols_logs:
    if c not in logs_df.columns:
        logs_df[c] = ""  # ì—†ìœ¼ë©´ ìƒì„±

# --- ì¥í•™ê¸ˆ ì§€ì›: ê¸ˆì•¡ íŒŒì‹± ì»¬ëŸ¼ ì¤€ë¹„ ---
if "maxAmount" not in scholar_df.columns:
    scholar_df["maxAmount"] = scholar_df.get("ì§€ì› ê¸ˆì•¡(ë²”ìœ„)", "").apply(parse_amount_to_max_per_year)

# =========================================================
# í™”ë©´: ì¼ì§€ ì‘ì„±
# =========================================================
if menu == "ì¼ì§€ ì‘ì„±":
    st.header("ğŸ“ ìƒë‹´ ì¼ì§€ ì‘ì„±")
    col_left, col_right = st.columns([1, 1])

    # í•™ìƒ ì„ íƒ (ì´ë¦„ìœ¼ë¡œ)
    with col_left:
        names = students_df.get("ì´ë¦„", pd.Series([], dtype=str)).dropna().unique().tolist()
        selected_name = st.selectbox("í•™ìƒ ì„ íƒ(ì´ë¦„)", names, index=0 if names else None, placeholder="ì´ë¦„ì„ ì„ íƒí•˜ì„¸ìš”")

        if selected_name:
            row = students_df[students_df["ì´ë¦„"] == selected_name].iloc[0]
            grade = row.get("í•™ë…„", "")
            cls = row.get("ë°˜", "")
            num = row.get("ë²ˆí˜¸", "")
        else:
            grade = cls = num = ""

        c1, c2, c3 = st.columns(3)
        with c1:
            st.text_input("í•™ë…„", value=str(grade), disabled=True)
        with c2:
            st.text_input("ë°˜", value=str(cls), disabled=True)
        with c3:
            st.text_input("ë²ˆí˜¸", value=str(num), disabled=True)

    with col_right:
        location = st.radio("ìƒë‹´ ì¥ì†Œ", ["êµë¬´ì‹¤", "ìƒë‹´ì‹¤1", "ìƒë‹´ì‹¤2"], horizontal=True)
        content = st.text_area("ìƒë‹´ ë‚´ìš©(ì§ì ‘ ì…ë ¥)", height=180, placeholder="ìƒë‹´ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”â€¦")

    # (ì˜µì…˜) ê°„í¸ ìŒì„± íŒŒì¼ ì—…ë¡œë“œ
    st.caption("ğŸ™ï¸ ì„ íƒ: ìŒì„± íŒŒì¼ì„ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤(ì €ì¥ì€ ë§í¬ë§Œ ê¸°ë¡).")
    audio_file = st.file_uploader("ì˜¤ë””ì˜¤ ì—…ë¡œë“œ (.mp3/.wav/.m4a/.webm ë“±)", type=["mp3", "wav", "m4a", "webm"], accept_multiple_files=False)

    # ì‹¤ì œ ì €ì¥(ì“°ê¸°) ë˜ëŠ” ì„ì‹œ ì¶”ê°€(ì½ê¸° ì „ìš©)
    if st.button("ğŸ’¾ ì¼ì§€ ì €ì¥í•˜ê¸°", use_container_width=True):
        if not selected_name:
            st.warning("í•™ìƒì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        else:
            ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            audio_url = ""
            if audio_file:
                # Streamlit Cloudì—” ê³µìš© íŒŒì¼ì„œë²„ê°€ ì—†ìœ¼ë¯€ë¡œ URLì„ ë§Œë“¤ ìˆ˜ ì—†ìŒ.
                # ì‹¤ì œë¡œ ë“œë¼ì´ë¸Œì— ì˜¬ë¦¬ë ¤ë©´ ì„œë¹„ìŠ¤ê³„ì •+Drive API ì¶”ê°€ êµ¬í˜„ í•„ìš”.
                # ì—¬ê¸°ì„  íŒŒì¼ëª…ì„ ë©”ëª¨ í˜•íƒœë¡œë§Œ ë‚¨ê¹ë‹ˆë‹¤.
                audio_url = f"(ì²¨ë¶€ íŒŒì¼ëª…: {audio_file.name})"

            row_vals = [ts, location, str(grade), str(cls), str(num), selected_name, content.strip(), audio_url]

            ok = False
            msg = ""
            if has_service_account():
                ok, msg = append_log_to_sheet(row_vals)
            else:
                msg = "í˜„ì¬ëŠ” ì½ê¸° ì „ìš© ëª¨ë“œì…ë‹ˆë‹¤. (ì„œë¹„ìŠ¤ ê³„ì •ì´ ì„¤ì •ë˜ë©´ ì‹œíŠ¸ì— ì§ì ‘ ì €ì¥ë©ë‹ˆë‹¤.)"

            if ok:
                st.success(msg)
                # ìºì‹œ ë¬´íš¨í™”í•˜ì—¬ 'ê¸°ë¡ ë³´ê¸°' íƒ­ ë°˜ì˜
                load_data.clear()
                students_df, logs_df, scholar_df = load_data()
            else:
                # ì½ê¸° ì „ìš© ëª¨ë“œì—ì„  UIì—ì„œ ì„ì‹œ ë°˜ì˜ë§Œ
                st.info(msg)
                with st.expander("ì´ë²ˆì— ì…ë ¥í•œ ë‚´ìš©(ë¯¸ë¦¬ë³´ê¸°)", expanded=True):
                    prev = pd.DataFrame([row_vals], columns=expected_cols_logs)
                    st.dataframe(prev, use_container_width=True)

# =========================================================
# í™”ë©´: ê¸°ë¡ ë³´ê¸°
# =========================================================
elif menu == "ê¸°ë¡ ë³´ê¸°":
    st.header("ğŸ“œ ìƒë‹´ ê¸°ë¡ ë³´ê¸°")

    names = students_df.get("ì´ë¦„", pd.Series([], dtype=str)).dropna().unique().tolist()
    sel_name = st.selectbox("í•™ìƒ ì„ íƒ", names, index=0 if names else None)

    if sel_name:
        sub = logs_df[logs_df["ì´ë¦„"] == sel_name].copy()
        if not sub.empty:
            # ìµœì‹ ìˆœìœ¼ë¡œ
            try:
                sub["íƒ€ì„ìŠ¤íƒ¬í”„"] = pd.to_datetime(sub["íƒ€ì„ìŠ¤íƒ¬í”„"], errors="coerce")
            except Exception:
                pass
            sub = sub.sort_values(by="íƒ€ì„ìŠ¤íƒ¬í”„", ascending=False)
            st.dataframe(sub, use_container_width=True)

            # í‚¤ì›Œë“œ ê°„ë‹¨ ì¶”ì¶œ
            all_text = " ".join(sub.get("ìƒë‹´ë‚´ìš©", pd.Series([], dtype=str)).dropna().tolist())
            items = process_text_for_keywords(all_text, topk=15)
            if items:
                st.markdown("**ìì£¼ ë“±ì¥í•œ í‚¤ì›Œë“œ**")
                st.markdown(chips_html(items), unsafe_allow_html=True)
            else:
                st.info("í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ì €ì¥ëœ ìƒë‹´ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")

# =========================================================
# í™”ë©´: ì „ì²´ ìš”ì•½
# =========================================================
elif menu == "ì „ì²´ ìš”ì•½":
    st.header("ğŸ“Š ì „ì²´ ìƒë‹´ ë‚´ìš© ìš”ì•½")

    # ì—°/ì›” ì„ íƒ (íƒ€ì„ìŠ¤íƒ¬í”„ì—ì„œ)
    logs_df["__ts"] = pd.to_datetime(logs_df["íƒ€ì„ìŠ¤íƒ¬í”„"], errors="coerce")
    years = sorted([int(y) for y in logs_df["__ts"].dt.year.dropna().unique().tolist()], reverse=True)
    year = st.selectbox("ë…„ë„", years, index=0 if years else None)
    months = list(range(1, 13))
    month = st.selectbox("ì›”", months, index=datetime.now().month - 1)

    if year and month:
        sub = logs_df[(logs_df["__ts"].dt.year == year) & (logs_df["__ts"].dt.month == month)]
        combined = " ".join(sub.get("ìƒë‹´ë‚´ìš©", pd.Series([], dtype=str)).dropna().tolist())
        items = process_text_for_keywords(combined, topk=50)

        if items:
            st.markdown("**ì›Œë“œí´ë¼ìš°ë“œ(ê°„ì´) / í‚¤ì›Œë“œ ë¹ˆë„ ìƒìœ„**")
            # ì›Œë“œí´ë¼ìš°ë“œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ì´, ê°„ì´ ë°”ì°¨íŠ¸ + ì¹©ìœ¼ë¡œ ëŒ€ì²´
            top_items = items[:20]
            # ì¹©
            st.markdown(chips_html(top_items[:15]), unsafe_allow_html=True)
            # ë°”ì°¨íŠ¸
            chart_df = pd.DataFrame(top_items, columns=["ë‹¨ì–´", "ë¹ˆë„"]).set_index("ë‹¨ì–´")
            st.bar_chart(chart_df)
        else:
            st.info("í•´ë‹¹ ê¸°ê°„ ìƒë‹´ ê¸°ë¡ì´ ì—†ê±°ë‚˜, ë¶„ì„í•  ë‹¨ì–´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")

# =========================================================
# í™”ë©´: ì¥í•™ê¸ˆ ì§€ì›
# =========================================================
elif menu == "ì¥í•™ê¸ˆ ì§€ì›":
    st.header("ğŸ“ ë§ì¶¤í˜• ì¥í•™ê¸ˆ ì°¾ê¸°")

    # ìµœì†Œ ê¸ˆì•¡(ë§Œì›) ìŠ¬ë¼ì´ë”
    min_amount = st.slider("í¬ë§ ìµœì†Œ ì§€ì› ê¸ˆì•¡(ì—°ê°„, ë§Œì›)", 0, 1000, 0, step=10)
    scholar_df["maxAmount"] = pd.to_numeric(scholar_df["maxAmount"], errors="coerce").fillna(0).astype(int)
    filtered = scholar_df[scholar_df["maxAmount"] >= min_amount].copy()

    st.write(f"ì´ **{len(filtered)}**ê±´ì˜ ì¥í•™ê¸ˆì´ ê²€ìƒ‰ë˜ì—ˆìŠµë‹ˆë‹¤.")
    # ë³´ê¸° ì¢‹ê²Œ ëª‡ ì»¬ëŸ¼ë§Œ ë…¸ì¶œ
    display_cols = []
    for c in ["ì¥í•™ëª…", "ìš´ì˜ ê¸°ê´€", "ì£¼ìš” ëŒ€ìƒ", "ì„ ë°œ ê¸°ì¤€ / í•„ìš” ì¡°ê±´", "ì§€ì› ê¸ˆì•¡(ë²”ìœ„)", "ì‹ ì²­ ë°©ì‹", "maxAmount"]:
        if c in filtered.columns:
            display_cols.append(c)
    if display_cols:
        st.dataframe(filtered[display_cols], use_container_width=True)
    else:
        st.dataframe(filtered, use_container_width=True)
